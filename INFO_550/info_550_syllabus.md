# INFO 550 - Software Engineering
## Instructor: Steve Pittard

## Prerequisites:
Working knowledge of R, Python, Java or consent of Instructor. A willingness to rapidly learn new concepts to address specific problems is essential. 

## Brief Description:
This course seeks to teach principles of software engineering through hands-on experience in constructing a “real life” project. During this course, the student will be exposed to a variety of programming technologies, analysis frameworks, and reproducible research tools. We will examine the role of Cloud Computing service models, (IaaS, PaaS, SaaS), and how they can accelerate the pace of research. Students will acquire hands on exposure and experience with machine learning techniques such as clustering ad regression as well as natural language processing techniques. Students will use their acquired knowledge to develop a final project application that will address some substantial problem or interest emerging within ‘big data contexts”. 

## Objectives/Outcomes:
To achieve greater practical facility with software approaches to download, cleanse, and manipulate real world data using currently accepted best practices with the R and Python languages as well as cloud computing. This course will build upon the student's existing knowledge of analytics, statistics, and visualization to complete a programming project involving a non-trivial data source. Upon completion of this course the student will be able to:

1. Approach large-scale data sources and implement software methods (existing and authored) to efficiently download, cleanse, and analyze the information. 

2. Identify and intelligently discuss the bottlenecks associated with managing large scale data and computation projects and identify appropriate strategies for addressing such challenges

3. Implement actual programming examples that demonstrate an understanding of the topics being presented during the course.

Each week will involve the introduction of a topic designed to improve the student's ability to approach large and/or unwieldy data sources in terms of wrangling, analysis, and visualization. This information will be used to obtain, clean, and analyze a large data set along with the construction of a relevant model and accompanying visualization. The end result will be implemented inside of a reproducible research document (e.g. Sweave). Assignments will be submitted to the student's GitHub account 

## Introduction to git and Github
We explore the use of collaborative software development tools, Students will learn to use git to effectively manage software projects while enabling public repositories on Github to facilitate collaborative work. Teams will use git to commit, fork, and branch their software projects and use the the built in Wiki capability of Github to publicize their work. 

## Introduction to reproducible research documents
In this class students will learn about the motivations for using reproducible research documents, the various types of reproducible documents, and how to select the best type for a give task. 

## Managing Large Data Sources - dplyr 
dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges such as large data sets and/or data residing in relational databases. We will discuss the split-apply-combine approach 

## Managing Large Data Sources – data.table
We will continue discussion and application of the the Split-Apply-Combine approach for reading in huge files. The R data.table table package will be introduced which offers fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, a fast friendly file reader and parallel file writer.

## Managing Large Data Sources – SQL
The history and use of relational databases will be discussed followed by demonstrations of basic SQL syntax and general use. Creating basic relational databases and interfacing with larger data sources will be discussed. Students will use sqlite3 to create and manage example data sources.

## Application Programming Interfaces – xml 
We will discuss the design goals of XML which emphasizes simplicity, generality, and usability of data exchange across the Internet. XML is widely used for the representation of arbitrary data structures such as those used in web services. In particular we will discuss scraping web sites and parsing XML files from the web using R packages such as XML. 

## Application Programming Interfaces – json
We will discuss JavaScript Object Notation or JSON that uses human readable text to transmit data objects consisting of attribute-value pairs and array data. In particular we will discuss scraping web sites and parsing files from the web using R packages such as JSON and jsonLite.

## Graphics Tour
We will take a tour of effective graphics packages and principles in R to understand conditioning, paneling, and the grammar of graphics. SaaS visualization tools such as mapping CartoDB, googleMaps, RgoogleVis, leaflest, and d3.js will be considered. The role of the API to work with public health and municipal data services (e.g. NCBI, Chicago Data Portal, WHO, Wunderground)

## Reusable Software Objects 
This class we be devoted to the motivation, creation, and use of reusable software objects in support of efficient application development. The R S3 and S4 object frameworks will be introduced. 

## Cloud Computing
We will examine the role of Cloud Computing service models, (IaaS, PaaS, SaaS), and how they can accelerate the pace of research. This class will focus particularly on IaaS and how on-demand, utility computing can simplify the management and analysis of obnoxiously large data sets
